{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 6us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 24s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_data = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = fashion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff344fec8d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainX[1], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/24/6ab1df969db228aed36a648a8959d1027099ce45fad67532b9673d533318/tqdm-4.23.4-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 662kB/s \n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import initializers\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "# Deterministic output.\n",
    "# Tired of seeing the same results every time? Remove the line below.\n",
    "np.random.seed(1000)\n",
    "\n",
    "# The results are a little better when the dimensionality of the random vector is only 10.\n",
    "# The dimensionality has been left at 100 for consistency with other GAN implementations.\n",
    "randomDim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = (trainX.astype(np.float32) - 127.5)/127.5\n",
    "trainX = trainX.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_dim=randomDim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(512))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(1024))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Dense(784, activation='tanh'))\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(512))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(256))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined network\n",
    "discriminator.trainable = False\n",
    "ganInput = Input(shape=(randomDim,))\n",
    "x = generator(ganInput)\n",
    "ganOutput = discriminator(x)\n",
    "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 468/468 [01:41<00:00,  4.61it/s]\n",
      "100%|██████████| 468/468 [01:48<00:00,  4.30it/s]\n",
      "100%|██████████| 468/468 [01:50<00:00,  4.23it/s]\n",
      "  1%|▏         | 7/468 [00:01<02:05,  3.67it/s]"
     ]
    }
   ],
   "source": [
    "X_train = trainX\n",
    "\n",
    "dLosses = []\n",
    "gLosses = []\n",
    "\n",
    "# Plot the loss from each batch\n",
    "def plotLoss(epoch):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(dLosses, label='Discriminitive loss')\n",
    "    plt.plot(gLosses, label='Generative loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('images/gan_loss_epoch_%d.png' % epoch)\n",
    "\n",
    "# Create a wall of generated MNIST images\n",
    "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, randomDim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "    generatedImages = generatedImages.reshape(examples, 28, 28)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/gan_generated_image_epoch_%d.png' % epoch)\n",
    "\n",
    "# Save the generator and discriminator networks (and weights) for later use\n",
    "def saveModels(epoch):\n",
    "    generator.save('models/gan_generator_epoch_%d.h5' % epoch)\n",
    "    discriminator.save('models/gan_discriminator_epoch_%d.h5' % epoch)\n",
    "\n",
    "def train(epochs=1, batchSize=128):\n",
    "    batchCount = X_train.shape[0] / batchSize\n",
    "    batchCount = int(batchCount)\n",
    "#     print 'Epochs:', epochs\n",
    "#     print 'Batch size:', batchSize\n",
    "#     print 'Batches per epoch:', batchCount\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        #print '-'*15, 'Epoch %d' % e, '-'*15\n",
    "        for _ in tqdm(range(batchCount)):\n",
    "            # Get a random set of input noise and images\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
    "\n",
    "            # Generate fake MNIST images\n",
    "            generatedImages = generator.predict(noise)\n",
    "            # print np.shape(imageBatch), np.shape(generatedImages)\n",
    "            X = np.concatenate([imageBatch, generatedImages])\n",
    "\n",
    "            # Labels for generated and real data\n",
    "            yDis = np.zeros(2*batchSize)\n",
    "            # One-sided label smoothing\n",
    "            yDis[:batchSize] = 0.9\n",
    "\n",
    "            # Train discriminator\n",
    "            discriminator.trainable = True\n",
    "            dloss = discriminator.train_on_batch(X, yDis)\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
    "            yGen = np.ones(batchSize)\n",
    "            discriminator.trainable = False\n",
    "            gloss = gan.train_on_batch(noise, yGen)\n",
    "\n",
    "        # Store loss of most recent batch from this epoch\n",
    "        dLosses.append(dloss)\n",
    "        gLosses.append(gloss)\n",
    "\n",
    "        if e == 1 or e % 20 == 0:\n",
    "            plotGeneratedImages(e)\n",
    "            saveModels(e)\n",
    "\n",
    "    # Plot losses from every epoch\n",
    "    plotLoss(e)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train(10, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
